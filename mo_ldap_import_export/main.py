# SPDX-FileCopyrightText: Magenta ApS <https://magenta.dk>
# SPDX-License-Identifier: MPL-2.0
"""Event handling."""

import json
from collections.abc import AsyncIterator
from collections.abc import Callable
from contextlib import AsyncExitStack
from contextlib import asynccontextmanager
from contextlib import suppress
from typing import Any
from uuid import UUID

import structlog
from fastapi import APIRouter
from fastapi import FastAPI
from fastapi import HTTPException
from fastapi import Query
from fastramqpi.events import Event
from fastramqpi.events import GraphQLEvents
from fastramqpi.events import Listener
from fastramqpi.events import Namespace
from fastramqpi.main import FastRAMQPI
from fastramqpi.ramqp.depends import handle_exclusively_decorator
from ldap3 import Connection
from ldap3.core.exceptions import LDAPNoSuchObjectResult
from ldap3.core.exceptions import LDAPObjectClassViolationResult
from ldap3.core.exceptions import LDAPUnwillingToPerformResult
from pydantic import BaseModel
from pydantic import Extra
from pydantic import ValidationError
from pydantic import parse_raw_as
from pydantic import validator
from structlog.contextvars import bound_contextvars

from . import depends
from .autogenerated_graphql_client import GraphQLClient
from .autogenerated_graphql_client import ListenerFilter
from .autogenerated_graphql_client import NamespaceFilter
from .config import Settings
from .converters import LdapConverter
from .customer_specific_checks import ExportChecks
from .customer_specific_checks import ImportChecks
from .database import Base
from .dataloaders import DataLoader
from .environments.main import construct_environment
from .exceptions import NoObjectsReturnedException
from .exceptions import ReadOnlyException
from .exceptions import SkipObject
from .import_export import SyncTool
from .ldap import check_ou_in_list_of_ous
from .ldap import configure_ldap_connection
from .ldap import ldap_healthcheck
from .ldap_amqp import ldap2mo_router
from .ldap_emit import publish_uuids
from .ldap_event_generator import LDAPEventGenerator
from .ldapapi import LDAPAPI
from .moapi import MOAPI
from .routes import construct_router
from .routes import ldap_event_router
from .types import EmployeeUUID
from .usernames import UserNameGenerator
from .utils import ensure_list

GRAPHQL_VERSION = 25

logger = structlog.stdlib.get_logger()

mo2ldap_router = APIRouter(prefix="/mo2ldap")


@mo2ldap_router.post("/address")
async def http_process_address(
    event: Event[UUID],
    settings: depends.Settings,
    graphql_client: depends.GraphQLClient,
) -> None:
    object_uuid = event.subject
    logger.info("Registered change in an address", object_uuid=object_uuid)
    result = await graphql_client.read_address_relation_uuids(object_uuid)
    person_uuids = {
        validity.employee_uuid
        for obj in result.objects
        for validity in obj.validities
        if validity.employee_uuid is not None
    }
    org_unit_uuids = {
        validity.org_unit_uuid
        for obj in result.objects
        for validity in obj.validities
        if validity.org_unit_uuid is not None
    }

    if person_uuids:
        # TODO: Add support for refreshing persons with a certain address directly
        me = await graphql_client.who_am_i()
        listeners = await graphql_client.read_event_listeners(
            filter=ListenerFilter(
                namespaces=NamespaceFilter(names=["mo"]),
                owners=[me.actor.uuid],
                user_keys=[
                    f"{settings.event_namespace}_internal_process_person",
                    f"{settings.event_namespace}_internal_reconcile_person",
                ]
                + [
                    f"{settings.event_namespace}_{mapping.identifier}"
                    for mapping in settings.conversion_mapping.mo_to_ldap
                    if mapping.routing_key == "person"
                ],
            ),
        )
        for listener in listeners.objects:
            await graphql_client.person_refresh(
                uuids=list(person_uuids),
                listener=listener.uuid,
            )
    if org_unit_uuids:
        me = await graphql_client.who_am_i()
        listeners = await graphql_client.read_event_listeners(
            filter=ListenerFilter(
                namespaces=NamespaceFilter(names=["mo"]),
                owners=[me.actor.uuid],
                user_keys=[
                    f"{settings.event_namespace}_internal_process_org_unit",
                ]
                + [
                    f"{settings.event_namespace}_{mapping.identifier}"
                    for mapping in settings.conversion_mapping.mo_to_ldap
                    if mapping.routing_key == "org_unit"
                ],
            ),
        )
        for listener in listeners.objects:
            await graphql_client.org_unit_refresh(
                uuids=list(org_unit_uuids),
                listener=listener.uuid,
                owner=me.actor.uuid,
            )


@mo2ldap_router.post("/engagement")
async def http_process_engagement(
    event: Event[UUID],
    settings: depends.Settings,
    graphql_client: depends.GraphQLClient,
) -> None:
    object_uuid = event.subject
    logger.info("Registered change in an engagement", object_uuid=object_uuid)
    result = await graphql_client.read_engagement_employee_uuid(object_uuid)
    person_uuids = {
        validity.employee_uuid for obj in result.objects for validity in obj.validities
    }
    if not person_uuids:
        logger.warning("Unable to lookup Engagement", uuid=object_uuid)
        return
    # TODO: Add support for refreshing persons with a certain engagement directly
    me = await graphql_client.who_am_i()
    listeners = await graphql_client.read_event_listeners(
        filter=ListenerFilter(
            namespaces=NamespaceFilter(names=["mo"]),
            owners=[me.actor.uuid],
            user_keys=[
                f"{settings.event_namespace}_internal_process_person",
            ]
            + [
                f"{settings.event_namespace}_{mapping.identifier}"
                for mapping in settings.conversion_mapping.mo_to_ldap
                if mapping.routing_key == "person"
            ],
        ),
    )
    for listener in listeners.objects:
        await graphql_client.person_refresh(
            uuids=list(person_uuids),
            listener=listener.uuid,
        )


@mo2ldap_router.post("/ituser")
async def http_process_ituser(
    event: Event[UUID],
    settings: depends.Settings,
    graphql_client: depends.GraphQLClient,
) -> None:
    object_uuid = event.subject
    logger.info("Registered change in an ituser", object_uuid=object_uuid)
    result = await graphql_client.read_ituser_relation_uuids(object_uuid)
    person_uuids = {
        validity.employee_uuid
        for obj in result.objects
        for validity in obj.validities
        if validity.employee_uuid is not None
    }
    org_unit_uuids = {
        validity.org_unit_uuid
        for obj in result.objects
        for validity in obj.validities
        if validity.org_unit_uuid is not None
    }
    if person_uuids:
        # TODO: Add support for refreshing persons with a certain address directly
        me = await graphql_client.who_am_i()
        listeners = await graphql_client.read_event_listeners(
            filter=ListenerFilter(
                namespaces=NamespaceFilter(names=["mo"]),
                owners=[me.actor.uuid],
                user_keys=[
                    f"{settings.event_namespace}_internal_process_person",
                ]
                + [
                    f"{settings.event_namespace}_{mapping.identifier}"
                    for mapping in settings.conversion_mapping.mo_to_ldap
                    if mapping.routing_key == "person"
                ],
            ),
        )
        for listener in listeners.objects:
            await graphql_client.person_refresh(
                uuids=list(person_uuids),
                listener=listener.uuid,
            )
    if org_unit_uuids:
        me = await graphql_client.who_am_i()
        listeners = await graphql_client.read_event_listeners(
            filter=ListenerFilter(
                namespaces=NamespaceFilter(names=["mo"]),
                owners=[me.actor.uuid],
                user_keys=[
                    f"{settings.event_namespace}_internal_process_org_unit",
                ]
                + [
                    f"{settings.event_namespace}_{mapping.identifier}"
                    for mapping in settings.conversion_mapping.mo_to_ldap
                    if mapping.routing_key == "org_unit"
                ],
            ),
        )
        for listener in listeners.objects:
            await graphql_client.org_unit_refresh(
                uuids=list(org_unit_uuids),
                listener=listener.uuid,
            )


@mo2ldap_router.post("/person")
@handle_exclusively_decorator(key=lambda event, *_, **__: event.subject)
async def http_process_person(
    event: Event[EmployeeUUID],
    settings: depends.Settings,
    sync_tool: depends.SyncTool,
) -> dict[str, list[Any]]:
    object_uuid = event.subject
    logger.info("Registered change in a person", object_uuid=object_uuid)
    if object_uuid in settings.mo_uuids_to_ignore:
        logger.warning("MO event ignored due to ignore-list", uuid=object_uuid)
        return {}

    return await sync_tool.listen_to_changes_in_employees(object_uuid)


@mo2ldap_router.post("/reconcile")
async def http_reconcile_person(
    event: Event[UUID],
    settings: depends.Settings,
    dataloader: depends.DataLoader,
    graphql_client: depends.GraphQLClient,
) -> None:
    object_uuid = event.subject
    logger.info("Registered change in a person (Reconcile)", object_uuid=object_uuid)
    if object_uuid in settings.mo_uuids_to_ignore:
        logger.warning("MO event ignored due to ignore-list")
        return

    dns = await dataloader.find_mo_employee_dn(object_uuid)
    ldap_uuids = set()
    for dn in dns:
        with suppress(NoObjectsReturnedException):
            ldap_uuids.add(await dataloader.ldapapi.get_ldap_unique_ldap_uuid(dn))

    # We handle reconciliation by seeding events into the normal processing queue
    await publish_uuids(
        settings=settings, graphql_client=graphql_client, uuids=list(ldap_uuids)
    )


@mo2ldap_router.post("/org_unit")
async def http_process_org_unit(
    event: Event[UUID],
    settings: depends.Settings,
    graphql_client: depends.GraphQLClient,
) -> None:
    object_uuid = event.subject
    logger.info("Registered change in an org_unit", object_uuid=object_uuid)
    # In case the name of the org-unit changed, we need to publish an
    # "engagement" message for each of its employees. Because org-unit
    # LDAP mapping is primarily done through the "Engagement" json-key.
    me = await graphql_client.who_am_i()
    listeners = await graphql_client.read_event_listeners(
        filter=ListenerFilter(
            namespaces=NamespaceFilter(names=["mo"]),
            owners=[me.actor.uuid],
            user_keys=[
                f"{settings.event_namespace}_internal_process_engagement",
            ]
            + [
                f"{settings.event_namespace}_{mapping.identifier}"
                for mapping in settings.conversion_mapping.mo_to_ldap
                if mapping.routing_key == "engagement"
            ],
        ),
    )
    for listener in listeners.objects:
        await graphql_client.org_unit_engagements_refresh(
            listener=listener.uuid,
            org_unit_uuid=object_uuid,
        )


@asynccontextmanager
async def open_ldap_connection(ldap_connection: Connection) -> AsyncIterator[None]:
    """Open the LDAP connection during FastRAMQPI lifespan.

    Yields:
        None
    """
    with ldap_connection:
        yield


@asynccontextmanager
async def lifespan(
    fastramqpi: FastRAMQPI,
    settings: Settings,
) -> AsyncIterator[None]:
    async with AsyncExitStack() as stack:
        logger.info("Configuring LDAP connection")
        ldap_connection = configure_ldap_connection(settings)
        fastramqpi.add_context(ldap_connection=ldap_connection)
        fastramqpi.add_healthcheck(name="LDAPConnection", healthcheck=ldap_healthcheck)
        await stack.enter_async_context(open_ldap_connection(ldap_connection))

        context = fastramqpi.get_context()
        graphql_client: GraphQLClient = context["graphql_client"]

        logger.info("Initializing MOAPI")
        moapi = MOAPI(settings, graphql_client)

        logger.info("Initializing LDAPAPI")
        ldapapi = LDAPAPI(settings, ldap_connection)

        logger.info("Initializing username generator")
        username_generator = UserNameGenerator(settings, ldapapi.connection)

        logger.info("Initializing dataloader")
        dataloader = DataLoader(settings, moapi, ldapapi, username_generator)
        fastramqpi.add_context(dataloader=dataloader)

        logger.info("Initializing Import/Export checks")
        export_checks = ExportChecks(dataloader)
        import_checks = ImportChecks()

        logger.info("Initializing jinja template environment")
        template_environment = construct_environment(settings, dataloader)

        logger.info("Initializing converters")
        converter = LdapConverter(template_environment)
        fastramqpi.add_context(converter=converter)

        logger.info("Initializing Sync tool")
        sync_tool = SyncTool(
            dataloader,
            converter,
            export_checks,
            import_checks,
            settings,
            ldap_connection,
        )
        fastramqpi.add_context(sync_tool=sync_tool)

        logger.info("Initializing LDAP listener")
        ldap_event_generator = LDAPEventGenerator(
            sessionmaker=fastramqpi.get_context()["sessionmaker"],
            settings=settings,
            graphql_client=graphql_client,
            ldap_connection=ldap_connection,
        )
        fastramqpi.add_context(ldap_event_generator=ldap_event_generator)
        if settings.listen_to_changes_in_ldap:
            logger.info("Initializing LDAP event generator")
            await stack.enter_async_context(ldap_event_generator)
            fastramqpi.add_healthcheck(
                name="LDAPEventGenerator", healthcheck=ldap_event_generator.healthcheck
            )

        logger.info("Starting program")
        yield


class JinjaOutput(BaseModel, extra=Extra.forbid):
    dn: str
    create: bool
    attributes: dict[str, list[Any]]

    @validator("attributes", pre=True)
    def process_attributes(cls, v: dict[str, Any | None]) -> dict[str, list]:
        if not isinstance(v, dict):
            raise TypeError("attributes must be a dictionary")

        attributes = v
        # Convert None's to empty lists to avoid writing "None" in LDAP
        # Whenever a None is templated out we blank the value in LDAP
        attributes = {
            key: [] if value is None else value for key, value in attributes.items()
        }
        # Ensure that all values are lists
        attributes = {key: ensure_list(value) for key, value in attributes.items()}
        return attributes


def mo_to_ldap_handler(
    identifier: str,
    template_string: str,
    object_class: str,
) -> Callable:
    async def inner(
        exit_stack: depends.ExitStack,
        converter: depends.LdapConverter,
        dataloader: depends.DataLoader,
        event: Event[UUID],
        dry_run: bool = Query(False),
    ) -> None:
        uuid = event.subject
        exit_stack.enter_context(
            bound_contextvars(identifier=identifier, uuid=str(uuid))
        )
        logger.info("Registered change in handler")

        template = converter.environment.from_string(template_string)
        try:
            result = await template.render_async({"uuid": uuid})
        except SkipObject:
            logger.info("Skipping object as requested")
            return
        logger.debug("Rendered jinja template", result=result)

        try:
            parsed = parse_raw_as(JinjaOutput, result)
        except json.JSONDecodeError as exc:
            message = "Unable to parse Jinja template output as JSON"
            logger.exception(message, result=result)
            raise HTTPException(status_code=500, detail={"message": message}) from exc
        except ValidationError as exc:
            message = "Unable to parse Jinja template output as model"
            logger.exception(message, result=result)
            raise HTTPException(status_code=500, detail={"message": message}) from exc

        logger.debug("Parsed jinja template", parsed=parsed)

        ldapapi = dataloader.ldapapi
        try:
            await ldapapi.ensure_ldap_object(
                parsed.dn,
                parsed.attributes,
                object_class,
                parsed.create,
                dry_run=dry_run,
            )
        except NoObjectsReturnedException as exc:
            message = "Unable to find Jinja referenced dn"
            logger.exception(message)
            raise HTTPException(status_code=500, detail={"message": message}) from exc
        except LDAPUnwillingToPerformResult as exc:
            message = "The LDAP server was unwilling to perform the change"
            logger.exception(message)
            raise HTTPException(status_code=500, detail={"message": message}) from exc
        except LDAPObjectClassViolationResult as exc:
            message = "The LDAP server states that required attributes are missing"
            logger.exception(message)
            raise HTTPException(status_code=500, detail={"message": message}) from exc
        except LDAPNoSuchObjectResult as exc:
            message = "The LDAP server could not find the superior"
            logger.exception(message)
            raise HTTPException(status_code=500, detail={"message": message}) from exc
        except ReadOnlyException as exc:
            message = "LDAP connection is read-only"
            logger.exception(message)
            raise exc

    return inner


def create_fastramqpi(**kwargs: Any) -> FastRAMQPI:
    """FastRAMQPI factory.

    Returns:
        FastRAMQPI system.
    """
    logger.info("Retrieving settings")
    settings = Settings(**kwargs)

    # ldap_ou_for_new_users needs to be in the search base. Otherwise we cannot
    # find newly created users...
    check_ou_in_list_of_ous(
        settings.ldap_ou_for_new_users,
        settings.ldap_ous_to_search_in,
    )

    # We also need to check for permission to write to this OU
    check_ou_in_list_of_ous(
        settings.ldap_ou_for_new_users,
        settings.ldap_ous_to_write_to,
    )

    # GraphQL event listeners
    listeners: list[Listener] = []
    if settings.listen_to_changes_in_mo:
        # Static listeners
        listeners.extend(
            [
                Listener(
                    namespace="mo",
                    user_key=f"{settings.event_namespace}_internal_process_address",
                    routing_key="address",
                    path="/mo2ldap/address",
                    parallelism=3,
                ),
                Listener(
                    namespace="mo",
                    user_key=f"{settings.event_namespace}_internal_process_engagement",
                    routing_key="engagement",
                    path="/mo2ldap/engagement",
                    parallelism=3,
                ),
                Listener(
                    namespace="mo",
                    user_key=f"{settings.event_namespace}_internal_process_ituser",
                    routing_key="ituser",
                    path="/mo2ldap/ituser",
                    parallelism=3,
                ),
                Listener(
                    namespace="mo",
                    user_key=f"{settings.event_namespace}_internal_process_person",
                    routing_key="person",
                    path="/mo2ldap/person",
                    parallelism=3,
                ),
                Listener(
                    namespace="mo",
                    user_key=f"{settings.event_namespace}_internal_reconcile_person",
                    routing_key="person",
                    path="/mo2ldap/reconcile",
                    parallelism=3,
                ),
                Listener(
                    namespace="mo",
                    user_key=f"{settings.event_namespace}_internal_process_org_unit",
                    routing_key="org_unit",
                    path="/mo2ldap/org_unit",
                    parallelism=3,
                ),
            ]
        )
        # Dynamic listeners
        listeners.extend(
            Listener(
                namespace="mo",
                user_key=f"{settings.event_namespace}_{mapping.identifier}",
                routing_key=mapping.routing_key,
                path=f"/mo_to_ldap/{mapping.identifier}",
                parallelism=3,
            )
            for mapping in settings.conversion_mapping.mo_to_ldap
        )
    if settings.listen_to_changes_in_ldap:
        listeners.extend(
            [
                Listener(
                    namespace=settings.event_namespace,
                    user_key="internal_process_uuid",
                    routing_key="uuid",
                    path="/ldap2mo/uuid",
                    parallelism=3,
                ),
                Listener(
                    namespace=settings.event_namespace,
                    user_key="internal_reconcile_uuid",
                    routing_key="uuid",
                    path="/ldap2mo/reconcile",
                    parallelism=3,
                ),
            ]
        )

    logger.info("Setting up FastRAMQPI")
    fastramqpi = FastRAMQPI(
        application_name="ldap_ie",
        settings=settings.fastramqpi,
        graphql_version=GRAPHQL_VERSION,
        graphql_client_cls=GraphQLClient,
        database_metadata=Base.metadata,
        graphql_events=GraphQLEvents(
            declare_namespaces=[
                Namespace(name=settings.event_namespace),
            ],
            declare_listeners=listeners,
        ),
    )
    fastramqpi.add_context(settings=settings)

    # Install dynamic endpoints router
    router = APIRouter(prefix="/mo_to_ldap")
    for mapping in settings.conversion_mapping.mo_to_ldap:
        handler = mo_to_ldap_handler(
            mapping.identifier, mapping.template, mapping.object_class
        )
        router.post(f"/{mapping.identifier}")(handler)
    app = fastramqpi.get_app()
    app.include_router(router)

    fastramqpi.add_lifespan_manager(lifespan(fastramqpi, settings), 2000)

    return fastramqpi


def create_app(fastramqpi: FastRAMQPI | None = None, **kwargs: Any) -> FastAPI:
    """FastAPI application factory.

    Returns:
        FastAPI application.
    """
    if fastramqpi is None:
        fastramqpi = create_fastramqpi(**kwargs)
    assert fastramqpi is not None

    app = fastramqpi.get_app()
    settings = fastramqpi._context["user_context"]["settings"]
    app.include_router(construct_router(settings))
    app.include_router(mo2ldap_router)
    app.include_router(ldap2mo_router)
    app.include_router(ldap_event_router)

    return app
